---
title: "Appendix"
output:
  html_document: default
  pdf_document:
    keep_tex: yes
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = 'C:/Dropbox/TFMr/TFM_Rscripts')
```

``` {r, include = FALSE, echo = FALSE}
library(R.VALUE)
library(bnlearn)
library(gRain)
library(igraph)
library(shape)
library(flexclust)
library(transformeR)
library(parallel)
library(sfsmisc)

source("functions/downscaling/build.downscalingBN.R")
source("functions/downscaling/downscale.BN.R")
source("functions/plot.graph.functions/plot.DBN.R")
source("functions/downscaling/marginals.R")
source("functions/validation/c.table.R")
source("functions/validation/auc.DBN.R")
source("functions/validation/MI.vs.distance.R")
source("functions/downscaling/aux_functions/is.mostLikely.R")
source("functions/validation/c.table.rates.R")
```

We summarize in this appendix how to perform downscaling with the functions developed.

### Model Learning

First we load the example data sets, predictors from ERA INTERIM for the Iberian penynsula and observations.
```{r}
load("data/era_interim/predictors_iberia.Rdata")
global <- makeMultiGrid(q850.iberia, t850.iberia, z850.iberia)
load("data/VALUE_Iberia_tp")
local <- VALUE_Iberia_tp
```

`local` dataset is converted to precipitation absence/presence using the threshold $1$mm. Then we intersecate the predictors and predictands in order to have simultaneous historical observations. This is accomplished using `getTemporalIntersection()` function from `transformeR`:

```{r}
local$Data[ local$Data < 1] <-  0
local$Data[ local$Data >= 1] <-  1
global <- getTemporalIntersection(obs = local, prd = global, which.return = "prd")
```


The first step is to build the model. This is accomplished using the function `build.downscalingBN()`. 

```{r}
DBN1 <- build.downscalingBN(local, global, ncategories = 4)
```

The model is built. We can visualize the DAG using `plot.DBN()`, 

```{r}
plot.DBN(DBN1)
```


This is the most basic approach, uses categorization by node, using $4$ categories, as especified by the parameter `ncategories = 4`. All the options explained in section \ref{dtbn} can be done by using the argument `categorization.type`. It allows the options `"no"`, which must be used if predictors are already categorical, `"nodeClustering"` (Clustering is performed for each node), `"varsClustering"`, (Clustering for each variable per node creating the variable nodes at the same location), `"nodeSimple"`, (categorization is made using absolute cuts), `"varsSimple"` (Same as the previous one, using separate variables), `"nodeEven"` (quantile categorization), `"varsEven"`(same as previous one, by variable), `"atmosphere"` (Clustering is performed for all nodes at once condensing the atmosphere status). By default this option is set to `nodeSimple`. Clustering is performed using `flexclust` library, and the clustering parameters (Including $k$, the number of centroids) must be set with the argument `clustering.args.list`, which substitutes the `ncategories` parameter, and also note that it admits other clustering options like k-medians or k-medioids.

We can also set the boolean options `forbid.global.arcs` and `forbid.local.arcs`, which restrict the DAG arcs between $G$ and $D$ nodes and, as we can see from the previous plot, are set to `TRUE` and `FALSE`, respectivelly. The Bayesian network structure learning algorithm and parameter learning methods can be set with the parameters `bnlearning.algorithm` and `param.learning.method`. `bnlearning.algorithm` admits the constraint-based, score-based and hybrid algorithms implemented in `bnlearn` package (`?bnlearn`), and their local counterparts, that can be specified using the .local suffix to the name, e.g. `"hc.local"` to perform local hill climbing search. All the parameters for the learning algorithm, including `distance` if local learning is to be performed, must be specified using the `bnlearning.args.list` argument. By default the learning algorithm is set to `"hc"` (hill-climbing).

As an example, we will build the bayesian network performing categorization using `k-means` with $k=12$ clustering by variables, local learning using `iamb` algorithm (Incremental Association, check ?iamb) with mutual information test and euclidean distance set to $4$ without forbidding arcs between global nodes. The function also performs parameter learning, and can use bayes approach, setting `param.learning.method = "bayes"`, and Maximum Likelihood approach with `param.learning.method = "mle"`.

The function can parallelize certain processes, in particular the clustering process for each node and constraint-based algorithms, if `parallelize` argument is set to TRUE. If `n.cores` is not set the function uses `detectCores()-1` threads. The cluster type can be set with `cluster.type = "FORK"`, for unix based systems or `cluster.type = "PSOCK` for Windows systems.

```{r}
DBN2 <- build.downscalingBN(local, global, categorization.type = "varsClustering",
                           forbid.global.arcs = FALSE,
                           forbid.local.arcs = FALSE,
                           bnlearning.algorithm = "iamb.local", 
                           clustering.args.list = list(k = 12, family = kccaFamily("kmeans")), 
                           bnlearning.args.list = list(test = "mi", distance = 4),
                           parallelize = TRUE,
                           cluster.type = "PSOCK",
                           param.learning.method = "bayes"
                          )
```


The fourth option in section \ref{dtbn} can be accomplished using the parameter `two.step = TRUE`. Once this parameter is set to `TRUE`, `bnlearning.algorithm2` and `bnlearning.args.list2` are used for the second structure learning process. The parameter `return.first`, by default set to `FALSE`, makes the function return both DAGs as a list. Argument `forbid.local.arcs` is obviously ignored at the first phase and forbids the creation of new arcs between $D$ nodes at the second phase. As an example we learn a bayesian network in two steps combining several options above.
     
```{r}
DBN3 <- build.downscalingBN(local, global, categorization.type = "nodeEven",
                           forbid.global.arcs = TRUE,
                           forbid.local.arcs = TRUE,
                           bnlearning.algorithm = "gs", # grow-shrink
                           ncategories = 4,
                           bnlearning.args.list = list(test = "mi"),
                           parallelize = TRUE,
                           cluster.type = "PSOCK",
                           param.learning.method = "bayes",
                           two.step = TRUE,
                           return.first = TRUE,
                           bnlearning.algorithm2 = "hc.local",
                           bnlearning.args.list2 = list(distance = 3) 
                          )
```

Then we can plot the first graph to analyze the relationships built:

```{r}
plot.DBN(DBN3$first)
```

The final network is stored in `DBN3$last`. We will use this network in the following section.

```{r}
DBN <- DBN3$last
```

### Downscaling

We can select a subperiod to predict by using `transformeR` library function `subsetGrid()`:

```{r}
test <- subsetGrid(global, years = c(1991))
```

Then the function `downscale.BN()` uses the object built by build.downscalingBN() and the predictors and performs downscaling:

```{r}
downscaled <- downscale.BN(DBN , test , parallelize = TRUE,  prediction.type = "event")
```

Here the `parallelize` option should help a lot when a lot of observations are provided. With the option `prediction.type = "event"` the output is directly the most likely event as given by the threshold explained in chapter \ref{Cbayesiannetworks}. If set to `prediction.type = "probabilities"` it will return probability tables instead. The result is a matrix with the columns being the stations and the rows being the observations:

```{r}
downscaled[1:5,]
```

We can compare this to the real observations using the contingency table:

```{r}
real <- subsetGrid(local, years = c(1991))
c.table(downscaled, real$Data)
```

We can also compute the AUC, although we need to have the probability values:

```{r}
downscaled <- downscale.BN(DBN , test , parallelize = TRUE,  prediction.type = "probabilities")
aucS <- auc.DBN(downscaled = downscaled, 
                realData = real$Data, 
                plot.curves = FALSE)
aucS
```
